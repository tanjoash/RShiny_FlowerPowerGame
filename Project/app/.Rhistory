rbind(as.data.frame(list(name="batty",emoticon="/|\\ ^._.^ /|\\",pattern="/|\\ ^._.^ /|\\"))) %>%
rbind(as.data.frame(list(name="bored",emoticon="(-_-)",pattern="\\(\\-_\\-\\)"))) %>%
rbind(as.data.frame(list(name="depressed",emoticon="(︶︹︶)",pattern="\\(︶︹︶\\)")))
print(emoticons$emoticon)
randmessages <- map_chr(1:10,~ str_c("Message ",.," ",emoticons$emoticon[runif(1,1,nrow(emoticons)+1)]))
randmessages
randmessages <- NULL
for (i in 1:10){
# Generate a random uniform number between 1 and the number of rows plus 1
rnumber <- runif(1,1,nrow(emoticons)+1)
# Round the number down (it guaranteed to be one of c(1,2,...,nrow(emoticons)))
rindex <- as.integer(rnumber)
# Use that to get a random emoticon
remoticon <-  emoticons$emoticon[rindex]
# create a random message
rmessage <- str_c("Message ",i," ",remoticon)
# add it to our vector of messages
randmessages <- c(randmessages,rmessage)
}
randmessages
classifier <- function(message,emoticons){
emotion <- "None"
for (i in 1:nrow(emoticons)){
if (str_detect(message,emoticons$pattern[i])) emotion <- emoticons$name[i]
}
emotion
}
emotions <- NULL
for (i in 1:length(randmessages)){
message <- randmessages[i]
emotion <- classifier(randmessages[i],emoticons)
emotions <- c(emotions,emotion)
}
emoticons <- as.data.frame(list(name="happy",emoticon=":-)",pattern=":-\\)")) %>%
rbind(as.data.frame(list(name="sad",emoticon=":-(",pattern=":-\\("))) %>%
rbind(as.data.frame(list(name="afraid",emoticon="(ㆆ _ ㆆ)",pattern="\\(ㆆ _ ㆆ\\)"))) %>%
rbind(as.data.frame(list(name="angry",emoticon="•`_´•",pattern="•`_´•"))) %>%
rbind(as.data.frame(list(name="batty",emoticon="/|\\ ^._.^ /|\\",pattern="\\/\\|\\ \\^\\._\\.\\^ \\/\\|\\"))) %>%
rbind(as.data.frame(list(name="bored",emoticon="(-_-)",pattern="\\(\\-_\\-\\)"))) %>%
rbind(as.data.frame(list(name="depressed",emoticon="(︶︹︶)",pattern="\\(︶︹︶\\)")))
print(emoticons$emoticon)
randmessages <- map_chr(1:10,~ str_c("Message ",.," ",emoticons$emoticon[runif(1,1,nrow(emoticons)+1)]))
randmessages
randmessages <- NULL
for (i in 1:10){
# Generate a random uniform number between 1 and the number of rows plus 1
rnumber <- runif(1,1,nrow(emoticons)+1)
# Round the number down (it guaranteed to be one of c(1,2,...,nrow(emoticons)))
rindex <- as.integer(rnumber)
# Use that to get a random emoticon
remoticon <-  emoticons$emoticon[rindex]
# create a random message
rmessage <- str_c("Message ",i," ",remoticon)
# add it to our vector of messages
randmessages <- c(randmessages,rmessage)
}
randmessages
classifier <- function(message,emoticons){
emotion <- "None"
for (i in 1:nrow(emoticons)){
if (str_detect(message,emoticons$pattern[i])) emotion <- emoticons$name[i]
}
emotion
}
emotions <- NULL
for (i in 1:length(randmessages)){
message <- randmessages[i]
emotion <- classifier(randmessages[i],emoticons)
emotions <- c(emotions,emotion)
}
emoticons <- as.data.frame(list(name="happy",emoticon=":-)",pattern=":-\\)")) %>%
rbind(as.data.frame(list(name="sad",emoticon=":-(",pattern=":-\\("))) %>%
rbind(as.data.frame(list(name="afraid",emoticon="(ㆆ _ ㆆ)",pattern="\\(ㆆ _ ㆆ\\)"))) %>%
rbind(as.data.frame(list(name="angry",emoticon="•`_´•",pattern="•`_´•"))) %>%
rbind(as.data.frame(list(name="batty",emoticon="/|\\ ^._.^ /|\\",pattern="\\/|\\\\ \\^\\._\\.\\^ \\/\\|\\\\"))) %>%
rbind(as.data.frame(list(name="bored",emoticon="(-_-)",pattern="\\(\\-_\\-\\)"))) %>%
rbind(as.data.frame(list(name="depressed",emoticon="(︶︹︶)",pattern="\\(︶︹︶\\)")))
print(emoticons$emoticon)
randmessages <- map_chr(1:10,~ str_c("Message ",.," ",emoticons$emoticon[runif(1,1,nrow(emoticons)+1)]))
randmessages
randmessages <- NULL
for (i in 1:10){
# Generate a random uniform number between 1 and the number of rows plus 1
rnumber <- runif(1,1,nrow(emoticons)+1)
# Round the number down (it guaranteed to be one of c(1,2,...,nrow(emoticons)))
rindex <- as.integer(rnumber)
# Use that to get a random emoticon
remoticon <-  emoticons$emoticon[rindex]
# create a random message
rmessage <- str_c("Message ",i," ",remoticon)
# add it to our vector of messages
randmessages <- c(randmessages,rmessage)
}
randmessages
classifier <- function(message,emoticons){
emotion <- "None"
for (i in 1:nrow(emoticons)){
if (str_detect(message,emoticons$pattern[i])) emotion <- emoticons$name[i]
}
emotion
}
emotions <- NULL
for (i in 1:length(randmessages)){
message <- randmessages[i]
emotion <- classifier(randmessages[i],emoticons)
emotions <- c(emotions,emotion)
}
emotions
classifier <- function(message, emoticons) {
emotion <- "None"
map_chr(1:nrow(emoticons), ~ if (str_detect(message, emoticons$pattern[.])) emoticons$name[.] else emotion)
}
emotions <- map_chr(randmessages, ~ tail(classifier(.x, emoticons), 1))
emotions
classifier <- function(message, emoticons) {
emotion <- "None"
map_chr(1:nrow(emoticons), ~ if (str_detect(message, emoticons$pattern[.])) emoticons$name[.] else emotion)
}
emotions <- map_chr(randmessages, ~ classifier(.x, emoticons))
classifier <- function(message, emoticons) {
emotion <- "None"
map_chr(1:nrow(emoticons), ~ if (str_detect(message, emoticons$pattern[.])) emoticons$name[.] else emotion)
}
emotions <- map_chr(randmessages, ~ paste(classifier(.x, emoticons), collapse = ", "))
classifier <- function(message, emoticons) {
emotion <- "None"
map_chr(1:nrow(emoticons), ~ if (str_detect(message, emoticons$pattern[.])) emoticons$name[.] else emotion)
}
emotions <- map_chr(randmessages, ~ paste(classifier(.x, emoticons), collapse = ", "))
emotions
classifier <- function(message, emoticons) {
emotions <- character(length = nrow(emoticons))
for (i in 1:nrow(emoticons)) {
if (str_detect(message, emoticons$pattern[i])) emotions[i] <- emoticons$name[i]
}
emotions[emotions != ""]
}
emotions <- map_chr(randmessages, ~ paste(classifier(.x, emoticons), collapse = ", "))
emotions
shiny::runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Predict on the training data
P_train <- predict(rf_model, traindata)
# Convert predicted class labels to numeric
PredictedChoice_train <- as.numeric(P_train)
# Create a confusion table for training data
Tabtrain <- table(PredictedChoice_train, traindata$Choice)
# Print the confusion table for training data
print(Tabtrain)
# Predict on the test data
P_test <- predict(rf_model, testdata)
# Write the predicted choices to a CSV file
write.csv(P_test, "model2prediction.csv", row.names = FALSE)
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Predict on the training data
P_train <- predict(rf_model, traindata)
# Convert predicted class labels to numeric
PredictedChoice_train <- as.numeric(P_train)
# Create a confusion table for training data
Tabtrain <- table(PredictedChoice_train, traindata$Choice)
# Print the confusion table for training data
print(Tabtrain)
# Predict on the test data
P_test <- predict(rf_model, testdata)
# Write the predicted choices to a CSV file
write.csv(P_test, "model2prediction.csv", row.names = FALSE)
# Create a confusion table for training data
Tabtrain <- table(PredictedChoice_train, traindata$Choice)
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Predict on the training data
P_train <- predict(rf_model, traindata)
# Convert predicted class labels to numeric
PredictedChoice_train <- apply(P_train,1,which.max)
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Predict on the training data
P_train <- predict(rf_model, traindata)
# Convert predicted class labels to numeric
PredictedChoice_train <- as.numeric(P_train)
# Create a confusion table for training data
Tabtrain <- table(PredictedChoice_train, traindata$Choice)
# Print the confusion table for training data
print(Tabtrain)
# Predict on the test data
P_test <- predict(rf_model, testdata)
# Write the predicted choices to a CSV file
write.csv(P_test, "model2prediction.csv", row.names = FALSE)
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Predict on the training data
P_train <- predict(rf_model, traindata)
# Convert predicted class labels to numeric
ActualChoice <- traindata[,"Choice"]
PredictedChoice_train <- as.numeric(P_train)
# Create a confusion table for training data
Tabtrain <- table(PredictedChoice_train, ActualChoice)
# Print the confusion table for training data
print(Tabtrain)
# Predict on the test data
P_test <- predict(rf_model, testdata)
# Write the predicted choices to a CSV file
write.csv(P_test, "model2prediction.csv", row.names = FALSE)
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
str(traindata)
summary(traindata)
head(traindata)
?apply
traindata$Choice<- max.col(traindata[110:113])
table(traindata$Choice)
which(colnames(traindata)=="CC1")
which(colnames(traindata)=="Price4")
library(mlogit)
S <- dfidx(traindata, shape="wide", choice="Choice", sep="", varying = c(4:83), idx = c("No", "Case"))
head(S)
str(S)
M <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data=S)
summary(M)
M$logLik
ActualChoice <- traindata[,"Choice"]
P <- predict(M, newdata=S)
PredictedChoice <- apply(P,1,which.max)
Tabtrain=table(PredictedChoice, ActualChoice)
Tabtrain
acc<- sum(diag(Tabtrain))/sum (Tabtrain)
acc
# LOG LOSS
sum((traindata[,110:113]*log(P))) / -21565
### sorry ignore this block - Melvin
# Logloss after 1 hot encoding
#my_data <-max.col(P)
#write.csv(P, "prediction2.csv", row.names=FALSE)
#data <- data.frame(Category = my_data)
#encoded_data <- model.matrix(~ 0 + Category, data = data)
#onehotdata <- read.csv("prediction2.csv")
#sum((traindata[,110:113]*onehotdata)) / -21565
# adding random number to choice (just to dfidx)
testdata$Choice<- sample(1:4,nrow(testdata), replace=TRUE)
test <- dfidx(testdata, shape="wide", choice="Choice", sep="", varying = c(4:83), idx = c("No", "Case"))
#submissions want the P
P <- predict(M, newdata=test)
write.csv(P, "model1prediction.csv", row.names=FALSE)
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Predict on the training data
P_train <- predict(rf_model, traindata)
# Convert predicted class labels to numeric
ActualChoice <- traindata[,"Choice"]
PredictedChoice_train <- as.numeric(P_train)
# Create a confusion table for training data
Tabtrain <- table(PredictedChoice_train, ActualChoice)
# Print the confusion table for training data
print(Tabtrain)
# Predict on the test data
P_test <- predict(rf_model, testdata)
# Write the predicted choices to a CSV file
write.csv(P_test, "model2prediction.csv", row.names = FALSE)
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Predict on the training data
P_train <- predict(rf_model, traindata, type = "response")
# Convert predicted class labels to numeric
ActualChoice <- traindata[,"Choice"]
PredictedChoice_train <- as.numeric(P_train)
# Create a confusion table for training data
Tabtrain <- table(PredictedChoice_train, ActualChoice)
# Print the confusion table for training data
print(Tabtrain)
# Predict on the test data
P_test <- predict(rf_model, testdata)
# Write the predicted choices to a CSV file
write.csv(P_test, "model2prediction.csv", row.names = FALSE)
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Predict on the training data
P_train <- predict(rf_model, traindata, type = "response")
# Convert predicted class labels to numeric
ActualChoice <- traindata[,"Choice"]
PredictedChoice_train <- as.numeric(P_train)
head(PredictedChoice_train)
# Create a confusion table for training data
Tabtrain <- table(PredictedChoice_train, ActualChoice)
# Print the confusion table for training data
print(Tabtrain)
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- as.data.frame(sort(importance(rf_model), decreasing = TRUE))
top_20_predictors <- row.names(var_imp)[1:20]
# Modify the formula for the top 20 predictors
formula_str <- paste("Choice ~", paste(top_20_predictors, collapse = " + "))
# Fit the Random Forest model for classification
rf_model <- randomForest(as.formula(formula_str), data = traindata, ntree = 100)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- as.data.frame(sort(importance(rf_model), decreasing = TRUE))
top_20_predictors <- row.names(var_imp)[1:20]
# Modify the formula for the top 20 predictors
formula_str <- paste("Choice ~", paste(top_20_predictors, collapse = " + "))
# Refit the Random Forest model with the top 20 predictors
rf_model <- randomForest(as.formula(formula_str), data = traindata, ntree = 100)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- as.data.frame(sort(importance(rf_model), decreasing = TRUE))
top_20_predictors <- row.names(var_imp)[1:20]
# Modify the formula for the top 20 predictors
formula_str <- paste("Choice ~", paste(top_20_predictors, collapse = " + "))
print(formula_str)
# Refit the Random Forest model with the top 20 predictors
rf_model <- randomForest(as.formula(formula_str), data = traindata, ntree = 100)
library(randomForest)
# Read the data
traindata <- read.csv("train1.csv")
testdata <- read.csv("test1.csv")
# Convert the "Choice" variable to a factor for classification
traindata$Choice<- max.col(traindata[110:113])
traindata$Choice <- as.factor(traindata$Choice)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- as.data.frame(sort(importance(rf_model), decreasing = TRUE))
top_20_predictors <- row.names(var_imp)[1:20]
top_20_predictors
# Modify the formula for the top 20 predictors
formula_str <- paste("Choice ~", paste(top_20_predictors, collapse = " + "))
print(formula_str)
# Refit the Random Forest model with the top 20 predictors
rf_model <- randomForest(as.formula(formula_str), data = traindata, ntree = 100)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- as.data.frame(sort(importance(rf_model), decreasing = TRUE))
top_20_predictors <- rownames(head(var_imp, 20))
top_20_predictors
# Modify the formula for the top 20 predictors
formula_str <- paste("Choice ~", paste(top_20_predictors, collapse = " + "))
print(formula_str)
# Refit the Random Forest model with the top 20 predictors
rf_model <- randomForest(as.formula(formula_str), data = traindata, ntree = 100)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- as.data.frame(sort(importance(rf_model), decreasing = TRUE))
var_imp
top_20_predictors <- rownames(head(var_imp, 20))
top_20_predictors
# Modify the formula for the top 20 predictors
formula_str <- paste("Choice ~", paste(top_20_predictors, collapse = " + "))
print(formula_str)
# Refit the Random Forest model with the top 20 predictors
rf_model <- randomForest(as.formula(formula_str), data = traindata, ntree = 100)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- as.data.frame(sort(importance(rf_model), decreasing = TRUE))
head(var_imp)
top_20_predictors <- rownames(head(var_imp, 20))
top_20_predictors
# Modify the formula for the top 20 predictors
formula_str <- paste("Choice ~", paste(top_20_predictors, collapse = " + "))
print(formula_str)
# Refit the Random Forest model with the top 20 predictors
rf_model <- randomForest(as.formula(formula_str), data = traindata, ntree = 100)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- as.data.frame(sort(importance(rf_model), decreasing = TRUE))
print(var_imp)
top_20_predictors <- rownames(head(var_imp, 20))
top_20_predictors
# Modify the formula for the top 20 predictors
formula_str <- paste("Choice ~", paste(top_20_predictors, collapse = " + "))
print(formula_str)
# Refit the Random Forest model with the top 20 predictors
rf_model <- randomForest(as.formula(formula_str), data = traindata, ntree = 100)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- as.data.frame(sort(importance(rf_model), decreasing = TRUE))
print(var_imp)
head(var_imp)
str(var_imp)
top_20_predictors <- rownames(head(var_imp, 20))
top_20_predictors
# Modify the formula for the top 20 predictors
formula_str <- paste("Choice ~", paste(top_20_predictors, collapse = " + "))
print(formula_str)
# Refit the Random Forest model with the top 20 predictors
rf_model <- randomForest(as.formula(formula_str), data = traindata, ntree = 100)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- importance(rf_model)
# Convert to dataframe and add predictor names
var_imp_df <- data.frame(Predictor = names(var_imp), Importance = var_imp)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- importance(rf_model)
var_imp <- setNames(var_imp, names(var_imp))
# Convert to dataframe and add predictor names
var_imp_df <- data.frame(Predictor = names(var_imp), Importance = var_imp)
# Fit the Random Forest model for classification
rf_model <- randomForest(Choice ~ . - No - Case, data = traindata, ntree = 100)
# Feature selection: Get the top 20 most important predictors
var_imp <- importance(rf_model)
predictor_names <- colnames(traindata)[!colnames(traindata) %in% c("Choice", "No", "Case")]
# Convert to dataframe and add predictor names
var_imp_df <- data.frame(Predictor = names(var_imp), Importance = var_imp)
shiny::runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
shiny::runApp('GitHub/RShiny_FlowerPowerGame/Project/app')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
shiny::runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
modalDialog(
size = "l",
div(
id = "calendar-modal",
tags$img(src = "assets/calendar prompt font changed.png"),
actionButton("1_May", ),
actionButton("2_May"),
actionButton("2_May"),
actionButton("2_May"),
actionButton("2_May"),
)
)
shiny::runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
runApp('GitHub/RShiny_FlowerPowerGame/Project')
